교차 인지 레이어의 가중치는 행렬에 저장됩니다. 행렬은 기본적으로 엑셀 스프레드시트처럼 열과 행으로 나열된 숫자들에 불과합니다. LoRA 모델은 이러한 행렬에 가중치를 추가함으로써 모델을 미세 조정합니다.
LoRA 모델이 동일한 수의 가중치를 저장하면서도 파일 크기가 작은 이유는 뭘까요? LoRA는 행렬을 랭크가 낮은(low-rank)  두 개의  행렬로 분해하기 때문입니다. 이렇게 함으로써 훨씬 더 적은 숫자를 저장할 수 있습니다.

어떤 모델이 1000개의 행과 2000개의 열로 구성된 행렬을 가지고 있다고 가정하겠습니다. 그러면 그 모델 파일에는 2백만 (1000x2000)개의 숫자가 저장됩니다. LoRA는 이 행렬을 1000x2 행렬과 2x2000 행렬로 쪼갭니다. 이렇게 하면 총 6천개(1000x2 + 2x2000)의 숫자만 필요하고, 따라서 원래의 행렬에 비해 1/333 으로 줄어듭니다.이 때문에 LoRA 파일의 크기가 훨씬 작은 것입니다.

이 예제에서 LoRA에 저장되는 행렬의 랭크(rank)는 2입니다. 원래의 차원의 랭크는 2000 이니 훨씬 작죠. 그래서 저 랭크 행렬(low-rank matirix)라고 합니다.
